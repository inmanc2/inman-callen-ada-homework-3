---
title: "inman-callen-ada-homework-3"
author: "Callen Inman"
date: "4/19/2021"
output: html_document
---

```{r}

# loading packages and data set

library(lmodel2)

library(broom)

library(curl)

library(ggplot2)

f <- curl("https://github.com/inmanc2/ada-2021-datasets/raw/main/KamilarAndCooperData.csv")

primates <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)

head(primates)

# removing NAs

KamilarandCooper <- na.omit(primates)

summary(KamilarandCooper)


# Challenge 1, Part 1

# fitting a linear regression model for weaning age ~ brain size


m1 <- lm(formula = WeaningAge_d ~ Brain_Size_Species_Mean, data = KamilarandCooper)

m1

# adding confidence interval values

KamilarandCooper$LoCI <- predict(m1, newdata = KamilarandCooper, 
                        interval = "confidence", 
                        level = 0.9)[, 2]
KamilarandCooper$HiCI <- predict(m1, newdata = KamilarandCooper, 
                        interval = "confidence", 
                        level = 0.9)[, 3]

# adding predictions and prediction interval bands

pred.int <- predict(m1, interval = "prediction")
KamilarandCooper1 <- cbind(KamilarandCooper, pred.int)

# creating a scatterplot of the regression

p <- ggplot(KamilarandCooper1, aes(x = Brain_Size_Species_Mean, y = WeaningAge_d)) +
  geom_point() + 
  geom_smooth(method = "lm", aes(
      ymin = LoCI, ymax = HiCI, parse = TRUE, color = "gray")) + xlab("Mean Brain Size") + ylab("Mean Weaning Age") + 
  geom_line(aes(y = lwr, color = "blue"))+
    geom_line(aes(y = upr, color = "red"))+
    scale_color_discrete(name = "Legend", labels = c("Upper Prediction Interval", "Line of Best Fit", "Lower Prediction Interval"))

# making an object for the linear regression equation so that it can be displayed in the plot

lm_eq <- function(KamilarandCooper1){

    m1 <- lm(WeaningAge_d ~ Brain_Size_Species_Mean, KamilarandCooper1);

    eq <- substitute((y) == a + b %.% (x)*","~~(r)^2~"="~r2, 

         list(a = format(unname(coef(m1)[1]), digits = 3),

              b = format(unname(coef(m1)[2]), digits = 3),

             r2 = format(summary(m1)$r.squared, digits = 3)))

    as.character(as.expression(eq));

}

# adding regression equation label to plot

p1 <- p + geom_text(x = 250, y = 1500, label = lm_eq(KamilarandCooper1), parse = TRUE)

p1
                   
# The point estimate of the slope generated by this model is 2.159. The slope of this regression line represents the rate of change in mean brain size as mean weaning age changes. This regression line indicates that, for every change in mean brain size of 1 g, mean weaning age changes by about 2.159 days.

confint(m1, level = 0.9)

# There is a 90% chance that the true value of the slope (beta coefficient 1) lies between 1.65 and 2.67.

summary(m1)

# The p-value for the slope of the regression line is 1.79 * 10^-7. This is well below the 0.05 threshold, indicating that we can reject the hypothesis that the beta coefficient is not significantly different from 0.


# The code below generates an estimate and a prediction interval for the mean weaning age of a species with a mean brain size of 0.75 g.

pi <- predict(m1,
  newdata = data.frame(Brain_Size_Species_Mean = 750),
  interval = "prediction", level = 0.9
)

pi

# There is a 90% chance that a future observed mean Weaning Age value would fall between 1355 and 2243 days.I do not trust the model to make a good prediction for this value of Brain Size because there are so few Brain Size values above around 200 grams. The confidence interval for the same confidence level is much wider here as a result (it appears the prediction interval is wider here as well). I would expect the model to make much better predictions about mean weaning age where there is a larger cluster of values to draw on (so below brain sizes of 200 g).


# Challenge 1, Part 2

# making a log(Brain Size)~ log(WeaningAge) version of the same model

# fitting a linear regression model for log(weaning age) ~ log(brain size)


m2 <- lm(formula = log(WeaningAge_d) ~ log(Brain_Size_Species_Mean), data = KamilarandCooper)

m2

# adding confidence interval values

KamilarandCooper$LoCI1 <- predict(m2, newdata = KamilarandCooper, 
                        interval = "confidence", 
                        level = 0.9)[, 2]
KamilarandCooper$HiCI1 <- predict(m1, newdata = KamilarandCooper, 
                        interval = "confidence", 
                        level = 0.9)[, 3]

# adding predictions and prediction interval bands

pred.int1 <- predict(m2, interval = "prediction")
KamilarandCooper2 <- cbind(KamilarandCooper, pred.int1)

# creating a scatterplot of the regression

p1 <- ggplot(KamilarandCooper2, aes(x = log(Brain_Size_Species_Mean), y = log(WeaningAge_d))) +
  geom_point() + 
  geom_smooth(method = "lm", aes(
      ymin = LoCI1, ymax = HiCI1, parse = TRUE, color = "gray")) + xlab("Log of Mean Brain Size") + ylab("Log of Mean Weaning Age") + 
  geom_line(aes(y = lwr, color = "blue"))+
    geom_line(aes(y = upr, color = "red"))+
    scale_color_discrete(name = "Legend", labels = c("Upper Prediction Interval", "Line of Best Fit", "Lower Prediction Interval"))

# making an object for the linear regression equation so that it can be displayed in the plot

lm_eq1 <- function(KamilarandCooper2){

    m2 <- lm(log(WeaningAge_d) ~ log(Brain_Size_Species_Mean), KamilarandCooper2);

    eq <- substitute((y) == a + b %.% (x)*","~~(r)^2~"="~r2, 

         list(a = format(unname(coef(m1)[1]), digits = 3),

              b = format(unname(coef(m1)[2]), digits = 3),

             r2 = format(summary(m1)$r.squared, digits = 3)))

    as.character(as.expression(eq));

}

# adding regression equation label to plot

p2 <- p1 + geom_text(x = 250, y = 1500, label= lm_eq1(KamilarandCooper2), parse = TRUE)

p2

m2
                   
# The point estimate of the slope generated by this model is 0.6628. The slope of this regression line represents the rate of change in log of mean brain size as log of mean age changes. This regression line indicates that, for every change in log of mean brain size of 1, mean weaning age changes by about 0.6628.

confint(m2, level = 0.9)

# There is a 90% chance that the true value of the slope (beta coefficient 1) lies between 0.53 and 0.80.

summary(m2)

# The p-value for the slope of the regression line is 1.494 * 10^-8. This is well below the 0.05 threshold, indicating that we can reject the hypothesis that the beta coefficient is not significantly different from 0.


# The code below generates an estimate and a prediction interval for the mean weaning age of a species with a mean brain size of 0.75 g.

pi1 <- predict(m2,
  newdata = data.frame(Brain_Size_Species_Mean = log(750)),
  interval = "prediction", level = 0.9
)

pi1

# There is a 90% chance that a future observed mean Weaning Age value would fall between 3.40 and 4.97.I do not trust the model to make as good of a prediction for a 750 gram brain size (so 2.87 in the log scale) as much as for somewhat higher values between 4 and 5, where log of brain size values are more tightly clustered. 

# Overall, I think the log scale is better than the non-log scale for making predictions about new observations and estimating true values. The observations are more tightly clustered and the confidence interval does not have as wide a range as it does for parts of the normal plot, indicating that we could make tighter estimates of population values from our sample. 

```


```{r}
# CHALLENGE 2

library(lmodel2)
library(broom)
library(tidyverse)
library(manipulate)
library(patchwork)
library(infer)
library(dplyr)

m3 <- lm(formula = log(MeanGroupSize) ~ log(Body_mass_female_mean), data = KamilarandCooper1)


coef(m3)


# The slope (beta coefficient 1) is 0.2045, and the intercept (beta coefficient 0) is 0.7973.

# generating bootstrap replicates 


reps=1000
boot.intercept=numeric(reps)
boot.slope=numeric(reps)

for (i in 1:reps){
  boot.data=sample_n(KamilarandCooper1, nrow(KamilarandCooper1), replace=TRUE)
  boot.m3=lm(log(MeanGroupSize)~log(Body_mass_female_mean), data=boot.data)
  boot.intercept[i]=coef(boot.m3)[1]
  boot.slope[i]=coef(boot.m3)[2]
}

# generating histograms of bootstrapping distributions for each coefficient

hist(boot.intercept, main="Bootstrap distribution for intercept")

hist(boot.slope, main="Bootstrap distribution for slope")

# setting parameters in order to calculate confidence interval from boostrapping distribution

alpha <- 0.05
confidence_level <- 1 - alpha
p_lower <- alpha / 2
p_upper <- 1 - (alpha / 2)
degrees_of_freedom <- nrow(KamilarandCooper1) - 2
critical_value <- qt(p_upper, df = degrees_of_freedom)

SE.intercept = sd(boot.intercept) 
SE.slope = sd(boot.slope)

# calculating CIs from bootstrapping
CI.lower.int = mean(boot.intercept) - SE.intercept * critical_value 
CI.upper.int = mean(boot.intercept) + SE.intercept * critical_value
CI.lower.slope = mean(boot.slope) - SE.slope * critical_value
CI.upper.slope = mean(boot.slope) + SE.slope * critical_value

# CI of intercept calculated from bootstrapping
CI.lower.int
CI.upper.int

confint(m3)

# 95% CI for the intercept, as calculated from bootstrapping, is from -2.746947 to 4.0854. 95% CI, as calculated using the confint function on the model, is from -2.299340 to 3.8939810, and these are quite similar to the values calculated using bootstrapping.

CI.lower.slope

CI.upper.slope

# 95% CI for the slope, as calculated from bootstrapping, is from -0.18615 to 0.6267391. This is very similar to the 95% cI calculated directly from the original model using the confint function, which is from -0.1468343 to 0.5558817.



sd(boot.intercept) 
sd(boot.slope)

# The standard deviation of the intercept bootstrapping distribution is 1.654986. The standard deviation of the slope bootstrapping distribution is 0.1969305.



summary(m3)

# The standard error of both the intercept and the slope are very similar to the standard deviations for both bootstrapping distributions.





```


```{r}


# CHALLENGE 3


# Below I build the boot_lm function and output the coefficients using a data frame, as well as separate data frames for standard errors and confidence intervals.

# building boot_lm function

boot_lm <- function(d, model, conf.level = 0.95, reps = 1000) {
  
  # running model
  
  run_lm <- lm(model, data = d)
  
  # getting estimates of coefficients, standard errors, and confidence intervals generated by lm()
  
  lm_output <- cbind(run_lm$coefficients) 
  se_output <- cbind(summary(run_lm)$coefficients[,2]) 
  ci_output <- cbind(confint(run_lm, level = conf.level))
  
# creating a bootstrap sampling for loop so as to eventually calculate values from distribution
  
  bootstrap_output <- NULL  
  for (i in 1:reps) {
    boot <- d[sample(nrow(d), size = nrow(d), replace = TRUE), ]
    fit <- lm(model, data = boot)
    coeff <- rbind(fit$coefficients) 
    bootstrap_output <- rbind(bootstrap_output, coeff)
  }
  
  alpha <- 1 - conf.level
    
  # getting bootstrap estimates
  
  boot_mean <- cbind(colMeans(bootstrap_output))
  boot_SE <- sapply(as.data.frame(bootstrap_output), function(x) sd(x)) 
  boot_lower <- sapply(as.data.frame(bootstrap_output), function(x) quantile(x, (alpha/2)))
  boot_upper <- sapply(as.data.frame(bootstrap_output), function(x) quantile(x, (1-(alpha/2))))
  
  # creating a dataframe for output of estimates
  
  output <- as.data.frame(cbind(lm_output, se_output, ci_output, boot_mean, boot_SE, boot_lower, boot_upper)) 
  colnames(output) <- c("Estimate", "SE", "Lower_CI", "Upper_CI", "Bootstrap_Mean", "Bootstrap_SE", "Bootstrap_Lower_CI", "Bootstrap_Upper_CI") 
  
  return(output)
} 


boot_lm(d=KamilarandCooper1, model="log(MeanGroupSize) ~ log(Body_mass_female_mean)")
boot_lm(d=KamilarandCooper1, model="log(DayLength_km) ~ log(Body_mass_female_mean)")
boot_lm(d=KamilarandCooper1, model="log(DayLength_km) ~ log(Body_mass_female_mean) + log(MeanGroupSize)") 



```

```{r}

























```